{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRNN Base Structure (TODO Training and Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base structure of CRNN\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.features = nn.Sequential (\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3,3)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "        )\n",
    "\n",
    "        final_conv_height = 6\n",
    "        final_conv_width = 5\n",
    "        gru_input_size = 256 * final_conv_width\n",
    "\n",
    "        totalInstruments = 3\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=768, \n",
    "            hidden_size=256, \n",
    "            batch_first=True\n",
    "        )\n",
    "        # out_features is technically 18 in paper, but realistically 3 at the beginning\n",
    "        self.fc = nn.Linear(in_features=256, out_features=totalInstruments)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # Pass input through convolutional layers\n",
    "        conv_output = self.features(input)\n",
    "        \n",
    "        # Get the batch size (B), and the number of feature maps (C), height (H), and width (W)\n",
    "        B, C, H, W = conv_output.size()\n",
    "\n",
    "        # Reshape the output to treat the height 'H' as the sequence and combine the channels\n",
    "        # and width 'W' as features, which should have been calculated as 256*5\n",
    "        # Here we assume each timestep corresponds to a row in the feature maps\n",
    "        x = conv_output.view(B, H, C * W)  # Shape: (B, H, C*W)\n",
    "\n",
    "        # Pass the reshaped conv_output to the GRU\n",
    "        gru_output, _ = self.gru(x)\n",
    "\n",
    "        # Usually, you'd take just the last time step\n",
    "        last_time_step_output = gru_output[:, -1, :]\n",
    "\n",
    "        # Pass that through your fully connected layer\n",
    "        output = self.fc(last_time_step_output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def save_model(self, path: str):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load_model(*parameters, path: str):\n",
    "        loaded_model = CRNN(parameters)\n",
    "        loaded_model.load_state_dict(torch.load(path))\n",
    "        return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future stuff for training and accuracy of CNN\n",
    "import torch.optim as optim\n",
    "\n",
    "model = CRNN()\n",
    "lossAlg = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import logging, sys\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sys.path.append('/Users/adarshbharathwaj/Desktop/eng100/project3/ENGR_100_Project_3/src')\n",
    "from utils import *\n",
    "\n",
    "pathSTR = \"/Users/adarshbharathwaj/Desktop/eng100/project3/ENGR_100_Project_3/sample_audio_training/train\"\n",
    "\n",
    "# List to hold the names\n",
    "file_names = []\n",
    "labels = ['oboe', 'trumpet', 'violin']\n",
    "instrument_labels = []\n",
    "\n",
    "for root, dirs, files in os.walk(pathSTR):\n",
    "    for dir in dirs:\n",
    "        if dir in labels:\n",
    "            for file_name in os.listdir(os.path.join(root, dir)):\n",
    "                file_names.append(os.path.join(root, dir, file_name))\n",
    "                instrument_labels.append(dir)\n",
    "\n",
    "# Encoder mapping\n",
    "label_encoder = LabelEncoder()\n",
    "numeric_labels = label_encoder.fit_transform(instrument_labels)\n",
    "\n",
    "process_and_save_audio_hdf5(file_names, numeric_labels, \"trainData.h5\", 22050, True)\n",
    "\n",
    "pathSTR = \"/Users/adarshbharathwaj/Desktop/eng100/project3/ENGR_100_Project_3/sample_audio_training/train\"\n",
    "\n",
    "# List to hold the names\n",
    "file_names = []\n",
    "labels = ['oboe', 'trumpet', 'violin']\n",
    "instrument_labels = []\n",
    "\n",
    "for root, dirs, files in os.walk(pathSTR):\n",
    "    for dir in dirs:\n",
    "        if dir in labels:\n",
    "            for file_name in os.listdir(os.path.join(root, dir)):\n",
    "                file_names.append(os.path.join(root, dir, file_name))\n",
    "                instrument_labels.append(dir)\n",
    "\n",
    "# Encoder mapping\n",
    "label_encoder = LabelEncoder()\n",
    "numeric_labels = label_encoder.fit_transform(instrument_labels)\n",
    "\n",
    "process_and_save_audio_hdf5(file_names, numeric_labels, \"testData.h5\", 22050, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.file_path = path\n",
    "        self.file = h5py.File(self.file_path, 'r')\n",
    "        self.features = self.file['features']\n",
    "        self.labels = self.file['labels']\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.file['overall_metadata'][2])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = torch.tensor(self.features[idx], dtype=torch.float32).reshape(1, 96, 87)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return feature, label\n",
    "    \n",
    "    def close(self):\n",
    "        self.file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "import time\n",
    "logging.basicConfig(stream=sys.stderr, level=logging.INFO)\n",
    "\n",
    "def train_model(\n",
    "        model, train_dataloader, validation_dataloader, criterion, optimizer, epochs = 1\n",
    ") -> Tuple[list, list]:\n",
    "    train_accuracies = []\n",
    "    validation_accuracies = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        for data, labels in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            predicted = torch.sigmoid(outputs) > 0.5\n",
    "            correct_predictions += (predicted == labels).float().sum()\n",
    "            total_predictions += torch.numel(labels)\n",
    "\n",
    "        train_accuracy = correct_predictions / total_predictions\n",
    "        train_accuracies.append(train_accuracy.item())\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct_predictions = 0\n",
    "            total_predictions = 0\n",
    "            for data, labels in validation_dataloader:\n",
    "                outputs = model(data)\n",
    "                predicted = torch.sigmoid(outputs) > 0.5\n",
    "                correct_predictions = (predicted == labels).float().sum()\n",
    "                total_predictions += torch.numel(labels)\n",
    "\n",
    "            validation_accuracy = correct_predictions / total_predictions\n",
    "            validation_accuracies.append(validation_accuracy)\n",
    "\n",
    "    # Time remaining counter\n",
    "    time_remaining = (epochs - (epoch+1)) * (\n",
    "        time.time() - start_time\n",
    "    )/(epoch+1)\n",
    "    hours, remainder = divmod(time_remaining, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    # Formatted time output\n",
    "    print(\n",
    "        f\"Time remaining: {int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n",
    "    )\n",
    "    \n",
    "    return train_accuracies, validation_accuracies\n",
    "\n",
    "def plot_accuracy(\n",
    "        train_accuracies:list, validation_accuracies:list, epoch_count: int\n",
    "):\n",
    "    epochs = range(1, epoch_count+1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\")\n",
    "    plt.plot(epochs, validation_accuracies, label=\"Validation Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def test_model(model, test_dataloader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        for data, labels in test_dataloader:\n",
    "            outputs = model(data)\n",
    "            predicted = torch.sigmoid(outputs) > 0.5\n",
    "            correct_predictions += (predicted == labels).float().sum()\n",
    "            total_predictions += torch.numel(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FrameDataset('trainData.h5')\n",
    "test_dataset = FrameDataset('testData.h5')\n",
    "\n",
    "train_size = int(0.8*len(train_dataset))\n",
    "validation_size = len(train_dataset) - train_size\n",
    "\n",
    "train_dataset, validation_dataset = random_split(train_dataset, [train_size, validation_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Time remaining: 00:00:00\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "plot_accuracy() missing 1 required positional argument: 'epoch_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_acc, valid_acc \u001b[38;5;241m=\u001b[39m train_model(model\u001b[38;5;241m=\u001b[39mmodel, train_dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader, validation_dataloader\u001b[38;5;241m=\u001b[39mvalidation_dataloader, criterion\u001b[38;5;241m=\u001b[39mlossAlg, optimizer\u001b[38;5;241m=\u001b[39moptimizer, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplot_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_accuracies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_accuracies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_acc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: plot_accuracy() missing 1 required positional argument: 'epoch_count'"
     ]
    }
   ],
   "source": [
    "train_acc, valid_acc = train_model(model=model, train_dataloader=train_dataloader, validation_dataloader=validation_dataloader, criterion=lossAlg, optimizer=optimizer, epochs=20)\n",
    "plot_accuracy(train_accuracies=train_acc, validation_accuracies=valid_acc, epoch=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
